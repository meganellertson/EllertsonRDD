---
title: "RDD Replication 1"
author: "Megan Ellertson"
date: "2/14/2021"
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}
library(readr)
library(tidyverse)
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(rdd)
library(haven)
library(estimatr)
library(rdrobust)
library(rddensity)
library(cli)
library(kableExtra)
library(stargazer)

library(Statamarkdown)
stataexe <-"C:/Program Files/Stata16/StataIC-64.exe"
knitr::opts_chunk$set(engine.path=list(stata=stataexe))


```


```{r, echo=FALSE, message=FALSE }

raw_hansen_dwi <- read_csv("Data/hansen_dwi.csv")

```
````{stata, echo=FALSE, message=FALSE}
use hansen_dwi.dta

```
##Question 1
The link below is connected to my github repository, which I have labeled (**EllertsonRDD**)[https://github.com/meganellertson/EllertsonRDD.git] due to the fact that I have another repository called RDD in my github currently. As an additional note, I began this assignment in both R and STATA. Given I am very new to R and have some prior experience in STATA, I wanted to take this opportunity to learn R and supplement what I was unable to figure out in R with the STATA software. Thus, I utilize both R and STATA code and output through this markdown page. My final do.file and figures from STATA are also located in the (**EllertsonRDD**)[https://github.com/meganellertson/EllertsonRDD.git] repository on github for specifics on my process in STATA if not fully displayed in the code for this markdown page. 

https://github.com/meganellertson/EllertsonRDD.git

##Question 2 

#Summary
*Punishment and Deterrence: Evidence from Drunk Driving* (Hansen, 2015) attempts to understand the effect of harsher punishments and sanctions on recidivism, particularly related to drunk driving and DUIs.  Hansen attempts to further the literature on contradictory conclusions provided by prior criminologists and economists on this topic. In this analysis Hansen analyzes the policy of the DUI, through the blood alcohol content thresholds and a quasi-experimental design to understand the effect that harsher punishment has on people's inclination to repeat a crime, specifically drinking and driving. Hansen utilizes DUI BAC test data from the state of Washington between 1999 and 2007, this specific time frame allows for the examination of a four year recivisims window as well as the constant nature of the BAC thresholds at 0.08 and 0.15 (aggravated DUI) after 1999.  The analysis ensures to look at individuals over the age of 21 given the behavior and punishment for drunk driving is very different. Hansen utilizes a McCrary Density test prior to local linear regression discontinuity design to ensure that the estimates are unbiased. Given the McCrary Density test, Hansen finds that there is no evidence of “endogenous sorting” or, more planely, that at the cutoff individuals are randomly getting slightly above or slightly below the DUI threshold. This means they cannot sort themselves or be sorted into or out of the DUI charge, it is just locally random. Hasen does confirm this through the density test, and thus can proceed with the regression discontinuity. He utilizes a local linear regression discontinuity to obtain the estimates with slopes that change at the discontinuity and with rectangular kernels.  The indicator variable, or dummy variable is when the BAC level is at or above 0.08 or in the case of the aggravated DUI: at or above 015. There are additional controls included such as age, gender, accident at the scene, and race. The running variable is the minimum between the two BAC tests provided at the scene which are usually very close in value. Hansen finds that these punishments do reduce recidivism. He finds that having a BAC at the DUI level or above decreases recidivism by 2 percentage points during the four years after the initial conviction (this is statistically significant at the 1%).  Similar results are found for the aggravated DUI level. The study also looks at how increasing severity of punishment impacts diversion. He finds that a 10% increase in sanctions for drunk driving reduces the act by 2.3%.  Hansen also addresses some other factors which contribute to recidivism rates such as incapacitation,rehabilitation and deterrence.  Deterrence ends up being the primary way for addressing this.Although Hansen also notes that the identification strategy is limited due to the inability to assess the effect of more severe punishments and testing for those who are first time offenders.

##Question 3

The cutoff variable is related to the running variable, in that it is a treatment or cutoff of the range of the running variable. In this case, the dummy variable that will be created is in relation to the BAC level of the individual, specifically at the point they would be given a DUI (BAC = 0.08).  In the paper Hansen also focuses on aggrivated DUI, but this analysis will be focusing on one cutoff at the 0.08 threshold. This can be done in STATA or R by simply creating a new variable contingent upon the value of the BAC variable which already exists in the data set. The following Summary Statistics table provides more isnight into the nature of the data. 
```{r, echo= FALSE, message=FALSE }
RDDdata <- raw_hansen_dwi %>%
  mutate(dui = car::Recode(bac1, "lo: 0.08=0; else = 1"))

``` 
```{stata, echo=FALSE, message=FALSE}

```

```{r, echo = FALSE }
sumstat = data.frame(
  Measure = c("Recidivism", "BAC", "DUI", "Male", "Accident", "Age", "White"),
  M_1  = c(mean(RDDdata$recidivism), mean(RDDdata$bac1), 
             mean(RDDdata$dui), mean(RDDdata$male), 
             mean(RDDdata$acc), mean(RDDdata$aged), 
             mean(RDDdata$white)),
  Sd_1 = c(sd(RDDdata$recidivism), sd(RDDdata$bac1),
              sd(RDDdata$dui), sd(RDDdata$male),
              sd(RDDdata$acc),sd(RDDdata$aged), 
              sd(RDDdata$white)),
  Min_1 = c(min(RDDdata$recidivism), min(RDDdata$bac1), 
              min(RDDdata$dui), min(RDDdata$male),
              min(RDDdata$acc),min(RDDdata$aged), 
              min(RDDdata$white)),
  Max_1 = c(max(RDDdata$recidivism), max(RDDdata$bac1), 
              max(RDDdata$dui), max(RDDdata$male), 
              max(RDDdata$acc), max(RDDdata$aged), 
              max(RDDdata$white))
            
)

kable(
  sumstat,
  col.names = c("Variables", "Mean", "Standard Deviation", "Minimum", "Maximum"),
  digits = 2,
  caption = "Summary Statistics Table"
)
```
The table shows that many of the variables of concern are binary and take the value of either 0 or 1. The data only looks at individuals of a legal drinking age, 21 and the highest age of 80. Much of the individuals pulled over for drunk driving are white with a mean of 0.84 and are usually men. The maximum BAC level reported in the data set is 0.45, which is much higher than even the aggravated BAC level. 

##Question 4
The following recreates the frequency distribution which is the method Hansen chooses to visualize the potential sorting behavior along the running variable which may be a form of manipulation. This is important to understand because, if individuals were able to control or sort themselves into the treatment group, it would take away from the ability to utilize the RDD method to draw any casual effects. The sorting would be cause for basis and would change the meaning of the results. 


```{r}
figure1 <- ggplot(RDDdata, aes(bac1)) +
  geom_histogram(binwidth = 0.001, color = "grey", fill = "white") 
figure1 + geom_vline(aes(xintercept = 0.08), color = "black", size = 1) +
  geom_vline(aes(xintercept = 0.15), color = "black", size = 1) +
  labs(title = "BAC Histogram", x = "bac1", y = "Frequency")
```
Visually, the frequency distribution appears very smooth, and there appears to be no bunching behavior around the cutoff which is indicated by the vertical line. The 0.15 line is included as well to remain as consistent with Hansen's figure as possible. Although visually, this appears may provide for some confidence to the lack of endogenous sorting, it may be more effective to use an additional density test, the McCrary Density test to ensure this conclusion.  
```{r}

density <- rddensity(RDDdata$bac1, c = 0.08, kernel = "uniform")
summary(density)
rdplotdensity(density, RDDdata$bac1)
```
The output of this test provide a p-value of 0.9595. Given the high p-value there is substantial evidence that there is no endogenous sorting impacting the data. This allows the RDD method to move forward with the ability to draw casual effect conclusions. Additionally, a density plot is produced which visualizes the cutoff of 0.08, the black line is prior to the cutoff and the red line is after the cutoff or the portion of the sample which would have received DUIs. It would make sense that there would not be sorting in the running variable for a few reasons, many of which are pointed out in Hansen's paper. Given the running variable is BAC, it is an extremely difficult measurement for an individual to control and particularly to control right at the DUI level. The BAC is very specific to the individuals body, and their activities, not to mention the difficulty in judgment one would suffer if they were even to attempt to control their BAC while drinking. Additionally, how the BAC is measured is extremely precise, therefore, it would be difficult to control for at such a specific level. 

A similar processes can be completed in STATA, as outputted below. Although conducted with similar commands, the package provided in STATA outputs a slightly different P-Value however,it still provides the same conclusions as drawn in R. 

Equation 1
$equation$

Question 5 
```{r} 

```


Question 6
```{r }


```

![testing](Figures/Linear.png)


Question 7
```{r}





```



Question 8
```{r}
categories <- RDDdata$bac1 
demmeans <- split(RDDdata$recidivism, cut(RDDdata$bac1, 100)) %>%
  lapply(mean) %>%
  unlist()
agg_RDDdata <- data.frame(recidivism = demmeans, bac1 = seq(0.01, 0.5, by = 0.01))
plottingdata <- RDDdata %>%
  mutate(gg_group = case_when(bac1>= 0.08 ~ 1, TRUE ~ 0))

ggplot(plottingdata, aes(bac1, recidivism)) +
  geom_point(aes(x=bac1, y = recidivism), data = agg_RDDdata) + xlim(0, 0.2) + ylim(0.08, 0.16) +
  stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm", formula = y ~ x + I(x^2)) +
  xlim(0,0.2) + ylim(0,1) +
  geom_vline(xintercept = 0.08)

ggplot(plottingdata, aes(bac1, recidivism)) +
  geom_point(aes(x=bac1, y = recidivism), data = agg_RDDdata) +
  stat_smooth(aes(bac1, recidivism, group = gg_group), method = "lm") +
  geom_vline(xintercept = 0.08)
  
```


Question 9

```{r}

```


